# ResGS: Residual Densification of 3D Gaussian for Efficient Detail Recovery

Yanzhe Lyu, Kai Cheng, Xin Kang, Xuejin Chen

[[arxiv]([[2412.07494\] ResGS: Residual Densification of 3D Gaussian for Efficient Detail Recovery](https://arxiv.org/abs/2412.07494))] 



![teaser](C:\Users\lyuyz\Desktop\workspace\ResGS\ResGS\assets\teaser.png)

This repository is the official implementation of "ResGS: Residual Densification of 3D Gaussian for Efficient Detail Recovery".

To overcome the limitations of the 3D-GS densification method, we propose a novel approach, **residual split**, which recovers more details and reduces redundancy. To support the method, we introduce a pipeline named ResGS. Experiments show that our ResGS can achieve SOTA rendering quality in novel view synthesis. Furthermore, consistent performance improvements can be achieved by applying our residual split on various 3D-GS variants, underscoring its versatility and potential for broader application in 3D-GS-based applications.

## Installation

```
# clone repository 
git clone https://github.com/Lyuyz5440/ResGS.git --recursive
cd ResGS

# create environment 
conda env create --file environment.yml
conda activate resgs
```

## Data

Please organize the data folder of a scene in the same way as 3D-GS. Specifically:

```
├──scene
   ├──images
      ├──image_0.jpg
      ├──image_1.jpg
      ├──image_2.jpg
      ├──...
   ├──sparse
      └──0
         ├──cameras.bin
         ├──images.bin
         ├──points3D.bin
```

To evaluate our method on the datasets used in the paper, please organize your dataset folders as follows:

```
├──data
   ├──MipNeRF
      ├──scene1
      ├──scene2
      ├──...
   ├──tandt
      ├──scene1
      ├──scene2
   ├──db
      ├──scene1
      ├──scene2
```

## Training

To train on a single scene, please use the following command:

```
python train.py -s <path to COLMAP or NeRF Synthetic dataset> --eval
```

The parameters of "train.py" are basically the same as 3D-GS, with the addition of several new ones:

<details>
<summary><span style="font-weight: bold;">New Command Line Arguments for train.py</span></summary>

  #### --device

 Set the GPU id to run the code, ```0``` by default.

  #### --residual_split_scale_div

 Scale divisor factor for the new Gaussian generated by the residual split, ```1.6``` by default.

  #### --opacity_reduce_weight

 Opacity multiplication factor for the original Gaussian performing residual split, ```0.3``` by default.

</details>
<br>

## Full Evaluation

To evaluate our method on all three datasets, we provide a script. Please run the following command:

```
python script.py --eval
```

<details>
<summary><span style="font-weight: bold;">Command Line Arguments for script.py</span></summary>

  #### --device

  Set the GPU id to run the code, ```0``` by default.

  #### --dataset

 Specify the dataset to evaluate the method on, ```""``` by default, meaning evaluation on all three datasets. More options are: ```tt``` for Tanks&Temples, ```db``` for Deep Blending, ```mip``` for Mip-NeRF360.

  #### --args

 Additional arguments to use in ```train.py```, ```""``` by default.

  #### --name

 Name for the script run, ```default``` by default.

  #### --eval

 Add this flag to run the evaluation script after training

  #### --save_path

 Path to save trained results and script output, ```trained/``` by default.

  #### --dataset_path

 Path for the three datasets, ```data/``` by default.

</details>
<br>

After training, if the ```--eval``` flag is set to true, ```script_eval.py``` will be run to render test images and calculate metrics. By default, the final folder should look like this:

```
├──trained
   ├──db
      ├──scene1
      ├──scene2
   ├──MipNeRF
      ├──scene1
      ├──scene2
      ├──...
   ├──tandt
      ├──scene1
      ├──scene2
   ├──db_eval.txt
   ├──MipNeRF_eval.txt
   ├──tandt_eval.txt
```

where ```db_eval.txt```, ```MipNeRF_eval.txt```, ```tandt_eval.txt``` contains the collected per scene and average results of the datasets.

## Citation

If you find our work helpful, please consider citing:

```
@inproceedings{Lyu2024ResGSRD,
  title={ResGS: Residual Densification of 3D Gaussian for Efficient Detail Recovery},
  author={Yanzhe Lyu and Kai Cheng and Xin Kang and Xuejin Chen},
  year={2024},
  eprint={2412.07494},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}
```

## Acknowledgment

The released version of our method chooses [AbsGS]([AbsGS](https://ty424.github.io/AbsGS.github.io/)) as its baseline, we thank them for their work. If you want to use our code, please also cite their paper. Additionally, please cite [3D-GS](https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/), as they are the original proposers of the 3D-GS framework.

```
@inproceedings{Ye2024AbsGSRF,
  title={AbsGS: Recovering Fine Details in 3D Gaussian Splatting},
  author={Zongxin Ye and Wenyu Li and Sidun Liu and Peng Qiao and Yong Dou},
  booktitle={ACM Multimedia},
  year={2024}
}

@Article{kerbl3Dgaussians,
      author       = {Kerbl, Bernhard and Kopanas, Georgios and Leimk{\"u}hler, Thomas and Drettakis, George},
      title        = {3D Gaussian Splatting for Real-Time Radiance Field Rendering},
      journal      = {ACM Transactions on Graphics},
      number       = {4},
      volume       = {42},
      month        = {July},
      year         = {2023},
      url          = {https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/}
}
```

